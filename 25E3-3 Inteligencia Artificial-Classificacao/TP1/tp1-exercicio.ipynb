{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e947d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do treino: (569, 8)\n",
      "Tamanho do teste: (143, 8)\n",
      "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "472         1       2    0  33.0      1      2  27.7500         2\n",
      "432         1       2    0  42.0      1      0  26.0000         2\n",
      "666         0       2    1  25.0      0      0  13.0000         2\n",
      "30          0       1    1  40.0      0      0  27.7208         0\n",
      "291         1       1    0  19.0      1      0  91.0792         0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Carregar o dataset\n",
    "url = \"https://github.com/cassiusf/datasets/raw/refs/heads/main/titanic_data.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1.1. Eliminar as variáveis “PassengerId”, “Name”, “Ticket” e “Cabin”\n",
    "df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], inplace=True)\n",
    "\n",
    "# 1.2. Eliminar observações com valores ausentes\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 1.3. Aplicar LabelEncoder em \"Embarked\" e \"Sex\"\n",
    "label_encoder = LabelEncoder()\n",
    "for col in [\"Embarked\", \"Sex\"]:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# 1.4. Separar o dataframe em Treino (80%) e Teste (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Saída\n",
    "print(f\"Tamanho do treino: {train_df.shape}\")\n",
    "print(f\"Tamanho do teste: {test_df.shape}\")\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7c09b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[63 17]\n",
      " [26 37]]\n",
      "\n",
      "True Negative (TN): 63\n",
      "False Positive (FP): 17\n",
      "False Negative (FN): 26\n",
      "True Positive (TP): 37\n",
      "\n",
      "Acurácia: 0.6993\n",
      "Precisão (Precision): 0.6852\n",
      "Revocação (Recall): 0.5873\n",
      "F1-score: 0.6325\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"Survived\"])\n",
    "y = df[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "#2. Treinar o modelo de Árvore de Decisão\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#2.1 Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "#2.3 e 2.4 Métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)\n",
    "print(f\"\\nTrue Negative (TN): {tn}\")\n",
    "print(f\"False Positive (FP): {fp}\")\n",
    "print(f\"False Negative (FN): {fn}\")\n",
    "print(f\"True Positive (TP): {tp}\")\n",
    "\n",
    "print(f\"\\nAcurácia: {accuracy:.4f}\")\n",
    "print(f\"Precisão (Precision): {precision:.4f}\")\n",
    "print(f\"Revocação (Recall): {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da42fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth  TN  FP  FN  TP  accuracy  precision    recall        f1\n",
      "0        NaN  63  17  25  38  0.706294   0.690909  0.603175  0.644068\n",
      "1        3.0  69  11  25  38  0.748252   0.775510  0.603175  0.678571\n",
      "2        5.0  76   4  33  30  0.741259   0.882353  0.476190  0.618557\n"
     ]
    }
   ],
   "source": [
    "# 3. Função para treinar e avaliar o modelo\n",
    "def avaliar_arvore(max_depth=None):\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    metrics = {\n",
    "        \"max_depth\": max_depth,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"TP\": tp,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# 3.Avaliar profundidades\n",
    "resultados = []\n",
    "for depth in [None, 3, 5]:  # None = default (sem limite)\n",
    "    resultados.append(avaliar_arvore(depth))\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "# 4. Apresente as visualizações da árvore original e das duas árvores criadas na questão 3.\n",
    "print(df_resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
